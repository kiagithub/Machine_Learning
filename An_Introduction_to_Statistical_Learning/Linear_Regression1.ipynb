{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.preprocessing import scale\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d # It is not explicitly used but is required for 3d projections \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Address\n",
    "path = 'C:/Users/kiawo/OneDrive/Documents/ML_learning/An_Introduction_to_Statistical_Learning/Data/'\n",
    "file = 'Advertising.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(path+file, index_col=0) # for removing Unnamed:0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>radio</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  radio  newspaper  sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$RSS = \\sum_{i=1}^n (y_i - \\hat y_i)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinary Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = df_raw['TV']\n",
    "y = df_raw['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiawo\\AppData\\Roaming\\Python\\Python36\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#adding constant for having intercept in sm\n",
    "X_with_const = sm.add_constant(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>TV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>230.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>44.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>17.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>151.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>180.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const     TV\n",
       "1    1.0  230.1\n",
       "2    1.0   44.5\n",
       "3    1.0   17.2\n",
       "4    1.0  151.5\n",
       "5    1.0  180.8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_with_const.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>sales</td>      <th>  R-squared:         </th> <td>   0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   312.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 22 Jan 2020</td> <th>  Prob (F-statistic):</th> <td>1.47e-42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:25:53</td>     <th>  Log-Likelihood:    </th> <td> -519.05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   1042.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   198</td>      <th>  BIC:               </th> <td>   1049.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    7.0326</td> <td>    0.458</td> <td>   15.360</td> <td> 0.000</td> <td>    6.130</td> <td>    7.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>    <td>    0.0475</td> <td>    0.003</td> <td>   17.668</td> <td> 0.000</td> <td>    0.042</td> <td>    0.053</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.531</td> <th>  Durbin-Watson:     </th> <td>   1.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.767</td> <th>  Jarque-Bera (JB):  </th> <td>   0.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.089</td> <th>  Prob(JB):          </th> <td>   0.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.779</td> <th>  Cond. No.          </th> <td>    338.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  sales   R-squared:                       0.612\n",
       "Model:                            OLS   Adj. R-squared:                  0.610\n",
       "Method:                 Least Squares   F-statistic:                     312.1\n",
       "Date:                Wed, 22 Jan 2020   Prob (F-statistic):           1.47e-42\n",
       "Time:                        22:25:53   Log-Likelihood:                -519.05\n",
       "No. Observations:                 200   AIC:                             1042.\n",
       "Df Residuals:                     198   BIC:                             1049.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          7.0326      0.458     15.360      0.000       6.130       7.935\n",
       "TV             0.0475      0.003     17.668      0.000       0.042       0.053\n",
       "==============================================================================\n",
       "Omnibus:                        0.531   Durbin-Watson:                   1.935\n",
       "Prob(Omnibus):                  0.767   Jarque-Bera (JB):                0.669\n",
       "Skew:                          -0.089   Prob(JB):                        0.716\n",
       "Kurtosis:                       2.779   Cond. No.                         338.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = sm.OLS(y, X_with_const).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DF Residual** – These are the degrees of freedom associated with the sources of variance.  The total variance has N-1 degrees of freedom.  The model degrees of freedom corresponds to the number of coefficients estimated minus 1.  Including the intercept, there are 2 coefficients, so the model has 2-1=1 degrees of freedom.  The Residual degrees of freedom is the DF total minus the DF model, 199 – 1 =198."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R-squared** – R-Squared is the proportion of variance in the dependent variable (sale) which can be explained by the independent variables (TV).  This is an overall measure of the strength of association and does not reflect the extent to which any particular independent variable is associated with the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adj R-squared** – This is an adjustment of the R-squared that penalizes the addition of extraneous predictors to the model. Adjusted R-squared is computed using the below formula where p is the number of predictors.\n",
    "\n",
    "$$ Adj R^2 = {1-(1-R^2){n-1 \\over n-p-1}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F-statistic** – This is the  is the Mean Square Model divided by the Mean Square Residual, yielding F=312.1.\n",
    "\n",
    "An F statistic is a value you get when you run an ANOVA test or a regression analysis to find out if the means between two populations are significantly different. It’s similar to a T statistic from a T-Test; A-T test will tell you if a single variable is statistically significant and an F test will tell you if a group of variables are jointly significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prob (F-statistic)** - This is the p-value associated with the above F-statistic. It is used in testing the null hypothesis that all of the model coefficients are 0.\n",
    "\n",
    "If you have significant result, it means that your results likely did not happen by chance. If you don’t have statistically significant results, you throw your test data out (as it doesn’t show anything!); in other words, you can’t reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AIC** - The Akaike information criterion (AIC) is an estimator of the relative quality of statistical models for a given set of data. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models. Thus, AIC provides a means for model selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BIC** - In statistics, the Bayesian information criterion (BIC) or Schwarz criterion (also SBC, SBIC) is a criterion for model selection among a finite set of models; the model with the lowest BIC is preferred. It is based, in part, on the likelihood function and it is closely related to the Akaike information criterion (AIC).\n",
    "\n",
    "AIC and BIC hold the same interpretation in terms of model comparison. That is, the larger difference in either AIC or BIC indicates stronger evidence for one model over the other (the lower the better)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**t**  – These are the t-statistics used in testing whether a given coefficient is significantly different from zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P>|t|** – This column shows the 2-tailed p-values used in testing the null hypothesis that the coefficient (parameter) is 0. Using an alpha of 0.05:\n",
    "\n",
    "  - The coefficient for TV is significantly different from 0 because its p-value is 0.000, which is smaller than 0.05. \n",
    "\n",
    "  - The constant (const) is significantly different from 0 at the 0.05 alpha level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[0.025\t0.975]** – These are the 95% confidence intervals for the coefficients.  The confidence intervals are related to the p-values such that the coefficient will not be statistically significant at alpha = .05 if the 95% confidence interval includes zero.  These confidence intervals can help you to put the estimate from the coefficient into perspective by seeing how much the value could vary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___sourced from: https://stats.idre.ucla.edu/stata/output/regression-analysis-2/ ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(df_raw.TV, df_raw.sales, order=1, ci=None, scatter_kws={'color':'r', 's':9})\n",
    "plt.xlim(-10,310)\n",
    "plt.ylim(ymin=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression coefficients (Ordinary Least Squares)\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "X = scale(df_raw.TV, with_mean=True, with_std=False).reshape(-1,1)\n",
    "y = df_raw.sales\n",
    "\n",
    "regr.fit(X,y)\n",
    "print(regr.intercept_)\n",
    "print(regr.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.Ridge (alpha = .5)\n",
    "reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg.intercept_)\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.Lasso (alpha = .1)\n",
    "reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reg.intercept_)\n",
    "print(reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid coordinates for plotting\n",
    "B0 = np.linspace(regr.intercept_-2, regr.intercept_+2, 50)\n",
    "B1 = np.linspace(regr.coef_-0.02, regr.coef_+0.02, 50)\n",
    "xx, yy = np.meshgrid(B0, B1, indexing='xy')\n",
    "Z = np.zeros((B0.size,B1.size))\n",
    "\n",
    "# Calculate Z-values (RSS) based on grid of coefficients\n",
    "for (i,j),v in np.ndenumerate(Z):\n",
    "    Z[i,j] =((y - (xx[i,j]+X.ravel()*yy[i,j]))**2).sum()/1000\n",
    "\n",
    "# Minimized RSS\n",
    "min_RSS = r'$\\beta_0$, $\\beta_1$ for minimized RSS'\n",
    "min_rss = np.sum((regr.intercept_+regr.coef_*X - y.values.reshape(-1,1))**2)/1000\n",
    "min_rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,6))\n",
    "fig.suptitle('RSS - Regression coefficients', fontsize=20)\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122, projection='3d')\n",
    "\n",
    "# Left plot\n",
    "CS = ax1.contour(xx, yy, Z, cmap=plt.cm.Set1, levels=[2.15, 2.2, 2.3, 2.5, 3])\n",
    "ax1.scatter(regr.intercept_, regr.coef_[0], c='r', label=min_RSS)\n",
    "ax1.clabel(CS, inline=True, fontsize=10, fmt='%1.1f')\n",
    "\n",
    "# Right plot\n",
    "ax2.plot_surface(xx, yy, Z, rstride=3, cstride=3, alpha=0.3)\n",
    "ax2.contour(xx, yy, Z, zdir='z', offset=Z.min(), cmap=plt.cm.Set1,\n",
    "            alpha=0.4, levels=[2.15, 2.2, 2.3, 2.5, 3])\n",
    "ax2.scatter3D(regr.intercept_, regr.coef_[0], min_rss, c='r', label=min_RSS)\n",
    "ax2.set_zlabel('RSS')\n",
    "ax2.set_zlim(Z.min(),Z.max())\n",
    "ax2.set_ylim(0.02,0.07)\n",
    "\n",
    "# settings common to both plots\n",
    "for ax in fig.axes:\n",
    "    ax.set_xlabel(r'$\\beta_0$', fontsize=17)\n",
    "    ax.set_ylabel(r'$\\beta_1$', fontsize=17)\n",
    "    ax.set_yticks([0.03,0.04,0.05,0.06])\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "est = smf.ols('sales ~ TV + radio + newspaper + TV*radio', df_raw).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Ordinary Least Squares Regression with a single variable we described the relationship between the predictor and the response with a straight line. In the case of multiple regression we extend this idea by fitting a  p-dimensional hyperplane to our p predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = df_raw[['TV','radio','newspaper']]\n",
    "y = df_raw['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding constant for having intercept in sm\n",
    "X_with_const = sm.add_constant(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = sm.OLS(y, X_with_const).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaction\n",
    "\n",
    "Interaction effects can be account for by including a new feature comprising the product of corresponding values from the interacting features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "$$\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_1}x_1+ \\hat{\\beta_2}x_2 + \\hat{\\beta_3}x_1x_2 + \\epsilon\\,$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $x_1$ and $x_2$ are the values of the two features, respectively and $x_1x_2$ represents the interaction between the two. It can be useful to use scikit-learn’s **PolynomialFeatures** to creative interaction terms for all combination of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int = df_raw[['TV','radio','newspaper']]\n",
    "y = df_raw['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int['TV_radio'] = X_int.TV*X_int.radio\n",
    "X_int.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding constant for having intercept in sm\n",
    "X_with_const = sm.add_constant(X_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = sm.OLS(y, X_with_const).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It means $(96.8 - 89.7)/(100 - 89.7) = 69\\%$ of variablity of **sale** that remains after fitting the model has been explained by interaction term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Address\n",
    "#path = '/Users/ljn197/Machine_learning/Data/'\n",
    "file = 'Auto.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(path+file)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing ? with NaN\n",
    "df_raw = df_raw.replace('?', np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['horsepower_c'] = df_raw['horsepower'].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x = 'horsepower_c',y='mpg', data=df_raw, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating extra variable to accomodate polynomial:\n",
    "$$mpg = \\beta_0 + \\beta_1\\times horsepower+ \\beta_2 \\times horsepower^2 + \\epsilon\\,$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['horsepower_2'] = df_raw['horsepower_c'].pow(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed = df_raw[['horsepower_c','horsepower_2','mpg']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int = feed[['horsepower_c','horsepower_2']]\n",
    "y = feed['mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding constant for having intercept in sm\n",
    "X_with_const = sm.add_constant(X_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = sm.OLS(y, X_with_const).fit()\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = est.predict(X_with_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(X_with_const['horsepower_c'], y_pred, fit_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2)\n",
    "sns.regplot(X_with_const['horsepower_c'], y_pred, fit_reg=False, ax=axs[0])\n",
    "sns.regplot(x = 'horsepower_c',y='mpg', data=df_raw, fit_reg=False, ax=axs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "sns.regplot(X_with_const['horsepower_c'], y_pred, fit_reg=False, ax=axs)\n",
    "sns.regplot(x = 'horsepower_c',y='mpg', data=df_raw, fit_reg=False, ax=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression with Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_int, y)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred_scikit = regr.predict(X_int) #scikit learn doesn't need the adding of constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_pred_scikit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots()\n",
    "sns.regplot(X_int['horsepower_c'], y, fit_reg=False, ax=axs)\n",
    "sns.regplot(x = X_int['horsepower_c'].values ,y=y_pred_scikit, fit_reg=True, order=2, scatter = True, ax=axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = pd.DataFrame(data =[X_int.horsepower_c.values, y_pred, y_pred_scikit.tolist()],index=['horsepower','Statsmodel','Scikit'])\n",
    "df_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Residual\n",
    "est.fittedvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most useful way to plot the residuals, though, is with your predicted values on the x-axis, and your residuals on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.residplot(x = y_pred, y= est.resid_pearson, lowess=True, color=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(y_pred_scikit, y_pred_scikit-y, color='b',label='Residual Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sum of squared (whitened) residuals.\n",
    "est.ssr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explained sum of squares\n",
    "est.ess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncentered sum of squares. Sum of the squared values of the (whitened) endogenous response variable.\n",
    "est.uncentered_tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The total (weighted) sum of squares centered about the mean.\n",
    "est.centered_tss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total mean squared error. Defined as the uncentered total sum of squares divided by n the number of observations.\n",
    "est.mse_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean squared error the model. This is the explained sum of squares divided by the model degrees of freedom.\n",
    "est.mse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean squared error of the residuals. The sum of squared residuals divided by the residual degrees of freedom.\n",
    "est.mse_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.resid_pearson # Residuals, normalized to have unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
